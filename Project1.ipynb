{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNmr_5MXuifw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUxAFDjE8XV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVFk3d4HvVV3",
        "colab_type": "text"
      },
      "source": [
        "### Software 1.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VWIUseJvJO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_string_from_class(class_x, x):\n",
        "  s = ['fizz', 'buzz', 'fizzbuzz']\n",
        "  if  class_x == 0:\n",
        "    return str(x)\n",
        "  else:\n",
        "    return s[class_x - 1]\n",
        "\n",
        "def get_class(x):\n",
        "  if x%15 == 0:\n",
        "    ans = 3\n",
        "  elif x%3 == 0:\n",
        "    ans = 1\n",
        "  elif x%5 == 0:\n",
        "    ans = 2\n",
        "  else:\n",
        "    ans = 0\n",
        "  return ans\n",
        "\n",
        "def test_software_1(x):\n",
        "  class_x = get_class(x)\n",
        "  return get_string_from_class(class_x, x)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ScWY5gO3IVD",
        "colab_type": "text"
      },
      "source": [
        "### Software 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_08mBil73HAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "from torch.autograd import Variable\n",
        "import pdb\n",
        "\n",
        "def get_bit_representation(x):\n",
        "  batch_size = 10\n",
        "  return np.array([int(i) for i in (\"0\"*size + \"{0:b}\".format(x))[-size:] ])\n",
        "\n",
        "\n",
        "class train_dataset(Dataset):\n",
        "  def __init__(self):\n",
        "    super(train_dataset, self).__init__()\n",
        "    self.arr = np.arange(101,1001)\n",
        "    traindata = np.stack([get_bit_representation(x) for x in self.arr])\n",
        "    self.traindata = np.array(traindata, dtype=np.float32)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    return self.traindata[i], get_class(self.arr[i])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.traindata)\n",
        "\n",
        "class test_dataset(Dataset):\n",
        "  def __init__(self, test_data):\n",
        "    super(test_dataset, self).__init__()\n",
        "    self.arr = np.array(test_data)\n",
        "    testdata = np.stack([get_bit_representation(x) for x in self.arr])\n",
        "    self.testdata = np.array(testdata, dtype=np.float32)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    return self.testdata[i], get_class(self.arr[i])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.testdata)\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, n_classes=4):\n",
        "    '''\n",
        "    Define the initialization function of LeNet, this function defines\n",
        "    the basic structure of the neural network\n",
        "    '''\n",
        "\n",
        "    super(MLP, self).__init__()\n",
        "    self.fc1 = nn.Linear(10, 64)\n",
        "    self.fc2 = nn.Linear(64, 128)\n",
        "    self.fc3 = nn.Linear(128, 64)\n",
        "    self.clf = nn.Linear(64, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 10)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    out = self.clf(x)\n",
        "    return out\n",
        "\n",
        "\n",
        "def train_one_epoch(model, trainloader, optimizer, device):\n",
        "  \"\"\" Training the model using the given dataloader for 1 epoch.\n",
        "\n",
        "  Input: Model, Dataset, optimizer, \n",
        "  \"\"\"\n",
        "\n",
        "  model.train()\n",
        "  avg_loss = AverageMeter(\"average-loss\")\n",
        "  for batch_idx, (img, target) in enumerate(trainloader):\n",
        "    img = Variable(img).to(device)\n",
        "    target = Variable(target).to(device)\n",
        "\n",
        "    # Zero out the gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward Propagation\n",
        "    prob = model(img)\n",
        "    loss = F.cross_entropy(prob, target)\n",
        "\n",
        "    # backward propagation\n",
        "    loss.backward()\n",
        "    avg_loss.update(loss, img.shape[0])\n",
        "\n",
        "    # Update the model parameters\n",
        "    optimizer.step()\n",
        "\n",
        "  return avg_loss.avg\n",
        "\n",
        "\n",
        "def train_MLP():\n",
        "  number_epochs = 500\n",
        "  device = torch.device('cpu')  # Replace with torch.device(\"cuda:0\") if you want to train on GPU\n",
        "  model = MLP(4).to(device)\n",
        "  dataset = train_dataset()\n",
        "  trainloader = DataLoader(dataset, batch_size=1024, shuffle=True)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  track_loss = []\n",
        "  for i in range(number_epochs):\n",
        "    loss = train_one_epoch(model, trainloader, optimizer, device)\n",
        "    track_loss.append(loss)\n",
        "    print(\"\\r{} out of {} done...\".format(i, number_epochs), end=\"\")\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(track_loss)\n",
        "  plt.title(\"training-loss-MLP\")\n",
        "  plt.savefig(\"./img/training_mlp.jpg\")\n",
        "\n",
        "  torch.save(model.state_dict(), \"./models/MLP.pt\")\n",
        "\n",
        "def test_software_2(model, testloader):\n",
        "    \"\"\" Training the model using the given dataloader for 1 epoch.\n",
        "\n",
        "    Input: Model, Dataset, optimizer,\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    avg_loss = AverageMeter(\"average-loss\")\n",
        "\n",
        "    y_gt = []\n",
        "    y_pred_label = []\n",
        "\n",
        "    for batch_idx, (img, y_true) in enumerate(testloader):\n",
        "        img = Variable(img)\n",
        "        y_true = Variable(y_true)\n",
        "        out = model(img)\n",
        "        y_pred = F.softmax(out, dim=1)\n",
        "        y_pred_label_tmp = torch.argmax(y_pred, dim=1)\n",
        "\n",
        "        loss = F.cross_entropy(y_pred, y_true)\n",
        "        avg_loss.update(loss, img.shape[0])\n",
        "\n",
        "        # Add the labels\n",
        "        y_gt += list(y_true.numpy())\n",
        "        y_pred_label += list(y_pred_label_tmp.numpy())\n",
        "\n",
        "    return avg_loss.avg, y_gt, y_pred_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_wy2D2M4oK1",
        "colab_type": "text"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONQLa8HYwc8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument('--test-data')\n",
        "\n",
        "  try:\n",
        "    get_ipython\n",
        "    list_args = ['--test-data', 'test_input.txt']\n",
        "    args = parser.parse_args(list_args)\n",
        "  except:\n",
        "    args = parser.parse_args()\n",
        "    args.test_data\n",
        "\n",
        "  with open(args.test_data, 'r') as fread:\n",
        "    test_data = []\n",
        "    for line in fread.readlines():\n",
        "      test_data.append(int(line))\n",
        "\n",
        "  # Output for Software1.0\n",
        "  with open(\"Software1.txt\", 'w') as fwrite:\n",
        "    for x in test_data:\n",
        "      out = test_software_1(x)\n",
        "      fwrite.write(\"{}\\n\".format(out))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AOgCQDfFfEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Prepare output for Software2.0\n",
        "  testdataset = test_dataset(test_data)\n",
        "  testloader = DataLoader(testdataset, batch_size=1024, shuffle=False)\n",
        "  model_MLP = MLP(4)\n",
        "  model_MLP.load_state_dict(torch.load(\"./models/MLP.pt\"))\n",
        "  loss_test, y_gt, y_pred = test_software_2(model_MLP, testloader)\n",
        "\n",
        "  # Output for Software2.0\n",
        "  with open(\"Software2.txt\", 'w') as fwrite:\n",
        "    for class_x, x in zip(y_pred, test_data):\n",
        "      out = get_string_from_class(class_x, x)\n",
        "      fwrite.write(\"{}\\n\".format(out))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}